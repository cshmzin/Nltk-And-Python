{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK基础.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZfkVYNcGejWuEHcVMMP4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cshmzin/Nltk-And-Python/blob/main/NLTK%E5%9F%BA%E7%A1%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f-sZALUYqTA"
      },
      "source": [
        "### NLTK基础\n",
        "* 分句\n",
        "* 分词\n",
        "* 训练自定义分句模型\n",
        "* 使用停用词"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G-MGD0iZvNI"
      },
      "source": [
        "#### 分句\n",
        "\n",
        "sent_tokenize函数使用了punkt模块，可以直接加载类一次，然后需要时调用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vCPxljjTkXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d26cc3-f0e2-40a6-b89c-d42e1f47441a"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "para = \"Hello World. It's good to see you. Thanks for buying this book.\"\n",
        "sent_tokenize(para)\n",
        "#--------------------------------------------------------------------------------------"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello World.', \"It's good to see you.\", 'Thanks for buying this book.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHCZk148ahu_",
        "outputId": "4f7f80b7-7552-413d-ad7c-e0d09729e4d3"
      },
      "source": [
        "import nltk.data\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/PY3/english.pickle')\n",
        "tokenizer.tokenize(para)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello World.', \"It's good to see you.\", 'Thanks for buying this book.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqEbgHxYZz8n"
      },
      "source": [
        "#### 分词\n",
        "同样与分句类似word_tokenize函数调用了TreebankWordTokenizer模块"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akQUjanKZQ_J",
        "outputId": "22efbc8e-4d0c-4893-f2fd-b3cf5a2fa1df"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize('Hello World.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'World', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymHLxwwwZ8t9",
        "outputId": "50984a36-ff32-4819-d994-b96be3343e9e"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize('Hello World.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'World', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "495krMkib42u",
        "outputId": "388f66a4-4059-48b4-a2d1-802e684f130d"
      },
      "source": [
        "word_tokenize(\"can't\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ca', \"n't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjspWYZwcE91",
        "outputId": "05fb34e8-12d1-41fe-df77-7600864be524"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "tokenizer.tokenize(\"Can't is a contraction.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Can', \"'\", 't', 'is', 'a', 'contraction', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErjkNmsTch8A"
      },
      "source": [
        "> 使用正则表达式标记语句"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEPcFz2PccPG",
        "outputId": "4ec561f0-e9f4-4ee3-c627-3e7a128fa135"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
        "tokenizer.tokenize(\"Can't is a contraction $$.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Can't\", 'is', 'a', 'contraction']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VDtnkNefhWv"
      },
      "source": [
        "#### 训练一个分句模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "7gwZjy2icq40",
        "outputId": "3386494e-0802-4f72-932b-d8542521c1b6"
      },
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.corpus import webtext\n",
        "#nltk.download('webtext')\n",
        "\n",
        "text = webtext.raw('overheard.txt')#读取文件\n",
        "sent_tokenizer = PunktSentenceTokenizer(text)\n",
        "sents1 = sent_tokenizer.tokenize(text)\n",
        "sents1[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'White guy: So, do you have any plans for this evening?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DimqO474fPwv",
        "outputId": "d9c017b7-57b5-4f45-b6af-561cc770c6db"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sents2 = sent_tokenize(text)\n",
        "print(sents2[0])\n",
        "\n",
        "print(sents1[678])\n",
        "print(sents2[678])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "White guy: So, do you have any plans for this evening?\n",
            "Girl: But you already have a Big Mac...\n",
            "Girl: But you already have a Big Mac...\n",
            "Hobo: Oh, this is all theatrical.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tym8lzWaggdw"
      },
      "source": [
        "#### 使用停用词"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROkpEPCpfv1G",
        "outputId": "f4e61b0c-a145-4483-e7eb-6e8bf5e34cca"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "english_stops = set(stopwords.words('english'))\n",
        "words = [\"Can't\", 'is', 'a', 'contraction']\n",
        "[word for word in words if word not in english_stops]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Can't\", 'contraction']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP7TWl2lgtcA"
      },
      "source": [
        "#stopwords.fileids()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc4cVir3hD72"
      },
      "source": [
        "#stopwords.words('english')"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}